import pandas as pd
import re
import sys
import unicodedata
from datetime import datetime
import os

# === Helper to clean description ===
def clean_description(text):
    text = str(text)
    text = re.sub(r"\b[A-Za-z]+(/[A-Za-z]+)+\b", "", text)
    text = re.sub(r"\b\d{1,2}[/-]\d{1,2}[/-]\d{2,4}\b", "", text)
    text = re.sub(r"=\s*\d+\.?\d*\s*(à¤šà¥Œ\.?\s*à¤«à¥\.?|à¤šà¥Œ\.?\s*à¤«à¥‚à¤Ÿ|à¤šà¥Œ\s*à¤«à¥|à¤šà¥Œ\s*à¤«à¥‚à¤Ÿ)", "", text)
    return text

# === Unicode normalization helper ===
def normalize_marathi(text: str) -> str:
    """Normalize Marathi text by removing invisible and punctuation characters."""
    if not isinstance(text, str):
        return ""
    text = unicodedata.normalize("NFKD", text)
    text = re.sub(r"[\s\u200b\u200c\u200d\u00a0\.\-]+", "", text)
    return text.strip().lower()

# === Area pattern ===
AREA_PATTERN = r"(\d+\.?\d*)\s*(à¤šà¥Œ\.?\s*à¤«à¥\.?|à¤šà¥Œ\s*à¤«à¥|à¤šà¥Œ\.?\s*à¤«à¥‚\.?|à¤šà¥Œ\s*à¤«à¥‚|à¤šà¥Œ\.?\s*à¤«à¥‚à¤Ÿ|à¤šà¥Œà¤«à¥à¤Ÿ|à¤šà¥Œ\s*à¤«à¥à¤Ÿ|à¤šà¥Œ\.?\s*à¤«à¥à¤Ÿà¤¾à¤¤|à¤šà¥Œ\s*à¤«à¥à¤Ÿà¤¾à¤¤)"

# === Shared parsing logic ===
def parse_contextual_areas(description, total_from_column):
    """Parse multiple contextual areas like RCC + Parking + Open etc."""
    desc_clean = clean_description(description)
    total_area = 0.0
    raw_patterns = []
    RCC = C = E = PR = OP = 0.0

    area_matches = list(re.finditer(AREA_PATTERN, desc_clean))
    for match in area_matches:
        num = float(match.group(1))
        total_area += num
        start_idx = match.start()
        context_start = max(0, start_idx - 60)
        context = desc_clean[context_start:start_idx]

        # detect context-sensitive allocations
        if re.search(r"à¤ªà¤¾à¤°à¥à¤•à¤¿à¤‚à¤—|parking", context, re.IGNORECASE):
            PR += num
        elif re.search(r"à¤†à¤°\s*\.?\s*à¤¸à¥€\s*\.?\s*à¤¸à¥€|rcc|à¤¨à¤¿à¤µà¤¾à¤¸à¥€", context):
            RCC += num
        elif re.search(r"à¤ªà¤¤à¥à¤°à¤¾|à¤ªà¤¤à¥à¤°à¤¾\s*à¤¶à¥‡à¤¡|à¤¸à¤¿à¤®à¥‡à¤‚à¤Ÿ\s*à¤ªà¤¤à¥à¤°à¤¾", context):
            E += num
        elif re.search(r"à¤•à¤šà¥à¤šà¥€\s*à¤ªà¤•à¥à¤•à¥€|à¤¸à¤¾à¤§à¥‡\s*à¤¶à¥‡à¤¡", context):
            C += num
        elif re.search(r"à¤®à¥‹à¤•à¤³à¥€\s*à¤œà¤¾à¤—à¤¾|à¤“à¤ªà¤¨\s*à¤¸à¥à¤ªà¥‡à¤¸", context):
            OP += num
        else:
            # default RCC if context is unknown
            RCC += num

        raw_patterns.append(match.group(0).strip())

    final_total = total_from_column if total_from_column > 0 else total_area
    assigned = RCC + C + E + PR + OP
    if final_total > assigned:
        RCC += final_total - assigned

    return ", ".join(raw_patterns) if raw_patterns else None, final_total, RCC, PR, C, E, OP


# === 2ï¸âƒ£ Main logic ===
def extract_area(description, totalarea, construction_type, unmatched_types):
    description = str(description).strip()
    total_from_column = float(totalarea) if pd.notna(totalarea) else 0.0
    ctype = normalize_marathi(construction_type)

    # ðŸ”§ Calculate all L*B patterns first
    desc_clean = clean_description(description)
    lb_matches = re.findall(r"(\d+\.?\d*)\s*[*xX]\s*(\d+\.?\d*)", desc_clean)
    total_lb_area = sum(float(l) * float(b) for l, b in lb_matches)

    # ðŸ§© CASE 1: à¤®à¤¿à¤¶à¥à¤° OR description contains "à¤ªà¤¾à¤°à¥à¤•à¤¿à¤‚à¤—" â†’ contextual parse
    if str(construction_type).strip() == "à¤®à¤¿à¤¶à¥à¤°" or re.search(r"à¤ªà¤¾à¤°à¥à¤•à¤¿à¤‚à¤—|parking", description, re.IGNORECASE):
        return parse_contextual_areas(description, total_from_column or total_lb_area)

    # ðŸ§© CASE 2: Non-à¤®à¤¿à¤¶à¥à¤° â†’ direct classification
    raw_patterns = [f"{l}*{b}" for l, b in lb_matches]
    area_matches = list(re.finditer(AREA_PATTERN, description))
    for m in area_matches:
        raw_patterns.append(m.group(0))

    # ðŸ”§ use either Excel totalarea or calculated LÃ—B
    final_total = total_from_column if total_from_column > 0 else total_lb_area

    RCC = C = E = PR = OP = 0.0

    # RCC
    if re.search(r"(à¤†à¤°à¤¸à¥€à¤¸à¥€à¤•à¤¿à¤‚à¤µà¤¾à¤²à¥‹à¤¡à¤¬à¥‡à¤…à¤°à¤¿à¤‚à¤—|à¤†à¤°à¤¸à¥€à¤¸à¥€à¤¶à¥‡à¤¡à¤•à¤¿à¤‚à¤µà¤¾à¤à¤‘à¤«à¥€à¤¸|à¤†à¤°à¤¸à¥€à¤¸à¥€à¤•à¤¿à¤‚à¤µà¤¾à¤²à¥‹à¤¡à¤¬à¥‡à¤…à¤°à¤¿à¤‚à¤—à¤«à¥à¤²à¤Ÿà¤¸à¤¿à¤¸à¥à¤Ÿà¤¿à¤®à¤‡à¤®à¤¾à¤°à¤¤à¤µà¤šà¤¾à¤³|rcc)", ctype):
        RCC = final_total
    # C
    elif "à¤•à¤šà¥à¤šà¥€à¤ªà¤•à¥à¤•à¥€à¤µà¥€à¤Ÿà¤®à¤¾à¤¤à¥€à¤šà¥€à¤›à¤¤à¤ªà¤¤à¥à¤°à¥à¤¯à¤¾à¤šà¥‡à¤µà¤—à¤µà¤¤à¤¾à¤šà¥‡à¤§à¤¾à¤¬à¥à¤¯à¤¾à¤šà¥‡" in ctype or "à¤¸à¤¾à¤§à¥‡à¤¶à¥‡à¤¡à¤•à¤¿à¤‚à¤µà¤¾à¤à¤‘à¤«à¥€à¤¸" in ctype:
        C = final_total
    # E
    elif "à¤ªà¤¤à¥à¤°à¥à¤¯à¤¾à¤šà¥€à¤Ÿà¥‡à¤®à¥à¤ªà¤°à¤°à¥€à¤¶à¥‡à¤¡à¥à¤¸" in ctype:
        E = final_total
    # PR
    elif "à¤ªà¤¾à¤°à¥à¤•à¤¿à¤‚à¤—à¤à¤°à¥€à¤¯à¤¾" in ctype:
        PR = final_total
    # OP
    elif "à¤®à¥‹à¤•à¤³à¥à¤¯à¤¾à¤œà¤®à¤¿à¤¨" in ctype:
        OP = final_total
    else:
        unmatched_types.add(str(construction_type))
        RCC = final_total  # default RCC

    return ", ".join(raw_patterns) if raw_patterns else None, final_total, RCC, PR, C, E, OP


def process_residential_data(file_path, log_callback=None):
    def log(msg):
        if log_callback:
            log_callback(msg)
        else:
            print(msg)

    log("ðŸ—ï¸ Starting Real Estate Data Cleaning (Final v8 with RCC + Parking Split)...")
    
    if not file_path:
        log("âŒ No file provided.")
        return

    log(f"ðŸ“‚ Reading file: {file_path}")

    try:
        df = pd.read_excel(file_path, engine="openpyxl")
    except Exception as e:
        log(f"âŒ Error reading file: {e}")
        return

    total_rows = len(df)
    log(f"ðŸ“Š Total rows to process: {total_rows}")

    # === 3ï¸âƒ£ Process all rows ===
    raw_texts, areas, RCCs, PRs, Cs, Es, OPs = [], [], [], [], [], [], []
    unmatched_types = set()

    for idx, row in df.iterrows():
        raw, area, rcc, pr, c, e, op = extract_area(
            row.get("description", ""),
            row.get("totalarea", 0),
            row.get("finalconstructiontype", ""),
            unmatched_types
        )
        raw_texts.append(raw)
        areas.append(area)
        RCCs.append(rcc)
        PRs.append(pr)
        Cs.append(c)
        Es.append(e)
        OPs.append(op)

        if (idx + 1) % 2000 == 0:
            log(f"âœ… Processed {idx + 1}/{total_rows} rows...")

    # === 4ï¸âƒ£ Add results ===
    df["Raw_Area_Text"] = raw_texts
    df["Area_R"] = areas
    df["RCC"] = RCCs
    df["PR"] = PRs
    df["C"] = Cs
    df["E"] = Es
    df["OP"] = OPs

    # === 5ï¸âƒ£ Output ===
    output_dir = os.path.dirname(file_path)
    output_file = os.path.join(output_dir, f"Residential_bifurcation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx")
    
    try:
        df.to_excel(output_file, index=False)
        log(f"ðŸŽ‰ Cleaning complete! (Smart Split for RCC + Parking + à¤®à¤¿à¤¶à¥à¤° + LÃ—B)")
        log(f"ðŸ“ Output saved as: {output_file}")
    except Exception as e:
        log(f"âŒ Error saving file: {e}")
        return

    # === 6ï¸âƒ£ Write unmatched safely ===
    if unmatched_types:
        unmatched_clean = [str(u) for u in unmatched_types if isinstance(u, str) and u.strip()]
        unmatched_clean = sorted(list(set(unmatched_clean)))
        unmatched_file = os.path.join(output_dir, "unmatched_construction_types.txt")
        with open(unmatched_file, "w", encoding="utf-8") as f:
            f.write("\n".join(unmatched_clean))
        log(f"âš ï¸ {len(unmatched_clean)} unmatched construction types written to {unmatched_file}")

    return output_file

if __name__ == "__main__":
    file_path = sys.argv[1] if len(sys.argv) > 1 else "input.xlsx"
    process_residential_data(file_path)
